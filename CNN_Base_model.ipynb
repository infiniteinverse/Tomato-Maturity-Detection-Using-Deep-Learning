{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99302e28-6107-4e6c-9711-0fb12b66dc03",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f92e6a08-02ed-45d8-bd7c-4384e14b9501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Conv2D, Input,MaxPooling2D,Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e89ddfbf-4726-455b-a82f-c2e6a65e0a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a2590f7-e151-4106-adf6-b96181aabc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e01717e-b43e-4a96-bdf2-e40cbb682b1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d043618-d256-41e2-be79-02ab75d6fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define parameters\n",
    "IMG_SIZE = (180,180)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "NUM_CLASSES = 5\n",
    "_input = Input((180,180,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5798e04-5943-47c2-b221-e7d8b4bd93a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4100 images belonging to 5 classes.\n",
      "Found 1022 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Path to your dataset\n",
    "DATASET_PATH = r'P:\\data sets\\Tomato_5_class\\Training_set'\n",
    "\n",
    "# Set up data generators with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # 20% for validation\n",
    ")\n",
    "\n",
    "# Training data generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',   # since you're using sparse labels\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# No augmentation for validation (just rescaling)\n",
    "val_aug = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "\n",
    "validation_generator = val_aug.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# # Validation data generator with augmentation\n",
    "# validation_generator = train_datagen.flow_from_directory(\n",
    "#     DATASET_PATH,\n",
    "#     target_size=IMG_SIZE,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     class_mode='sparse',\n",
    "#     subset='validation',\n",
    "#     shuffle=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed13d1bd-98ca-48b2-b773-599212140b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1275 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test data generator (no augmentation)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "TEST_DATASET_PATH = r'P:\\data sets\\Tomato_5_class\\Testing_set'\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DATASET_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='sparse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b75d09-0642-46de-bf2c-b994a9a57584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "163a34b1-0f1b-465d-95df-ddc49bb7249d",
   "metadata": {},
   "source": [
    "## VGG16 model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2fb83fb-d569-4d39-b652-14107aaae4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "# Constants\n",
    "# IMG_SIZE = IMG_SIZE\n",
    "# NUM_CLASSES = 5\n",
    "\n",
    "# Load VGG16 base (exclude top FC layers)\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "\n",
    "# Freeze the convolutional base\n",
    "base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13ce565c-62eb-44a8-b998-f3b9359f9636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom classification head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd3da2d5-fa79-428e-82ac-c25fbde7e7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "129/129 [==============================] - 88s 582ms/step - loss: 1.6410 - accuracy: 0.4076 - val_loss: 1.3425 - val_accuracy: 0.5225\n",
      "Epoch 2/5\n",
      "129/129 [==============================] - 42s 323ms/step - loss: 1.5539 - accuracy: 0.4605 - val_loss: 1.3266 - val_accuracy: 0.5235\n",
      "Epoch 3/5\n",
      "129/129 [==============================] - 45s 346ms/step - loss: 1.4837 - accuracy: 0.4832 - val_loss: 1.3133 - val_accuracy: 0.5235\n",
      "Epoch 4/5\n",
      "129/129 [==============================] - 46s 357ms/step - loss: 1.4392 - accuracy: 0.4885 - val_loss: 1.3039 - val_accuracy: 0.5294\n",
      "Epoch 5/5\n",
      "129/129 [==============================] - 42s 324ms/step - loss: 1.4122 - accuracy: 0.4973 - val_loss: 1.2953 - val_accuracy: 0.5313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24704fa8640>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the head (initial training)\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98954af6-bb3c-480d-8712-4021a4e59d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "129/129 [==============================] - 38s 292ms/step - loss: 1.3636 - accuracy: 0.5198 - val_loss: 1.2948 - val_accuracy: 0.5323\n",
      "Epoch 2/7\n",
      "129/129 [==============================] - 39s 304ms/step - loss: 1.3585 - accuracy: 0.5193 - val_loss: 1.2876 - val_accuracy: 0.5401\n",
      "Epoch 3/7\n",
      "129/129 [==============================] - 40s 313ms/step - loss: 1.3456 - accuracy: 0.5249 - val_loss: 1.2873 - val_accuracy: 0.5382\n",
      "Epoch 4/7\n",
      "129/129 [==============================] - 41s 314ms/step - loss: 1.3297 - accuracy: 0.5351 - val_loss: 1.2878 - val_accuracy: 0.5431\n",
      "Epoch 5/7\n",
      "129/129 [==============================] - 41s 314ms/step - loss: 1.3151 - accuracy: 0.5385 - val_loss: 1.2965 - val_accuracy: 0.5479\n",
      "Epoch 6/7\n",
      "129/129 [==============================] - 40s 309ms/step - loss: 1.3083 - accuracy: 0.5424 - val_loss: 1.2906 - val_accuracy: 0.5489\n",
      "Epoch 7/7\n",
      "129/129 [==============================] - 41s 316ms/step - loss: 1.3028 - accuracy: 0.5454 - val_loss: 1.2797 - val_accuracy: 0.5479\n"
     ]
    }
   ],
   "source": [
    "EPOCHS_ADDITIONAL = 7\n",
    "\n",
    "history_more = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS_ADDITIONAL,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82c5fc3f-086b-4471-bdf0-2dc98111b850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "129/129 [==============================] - 44s 324ms/step - loss: 1.1418 - accuracy: 0.5815 - val_loss: 1.0880 - val_accuracy: 0.5959\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 42s 325ms/step - loss: 1.0072 - accuracy: 0.6073 - val_loss: 1.0372 - val_accuracy: 0.6018\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 44s 340ms/step - loss: 0.9518 - accuracy: 0.6198 - val_loss: 0.9808 - val_accuracy: 0.6125\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 44s 342ms/step - loss: 0.9099 - accuracy: 0.6229 - val_loss: 0.9481 - val_accuracy: 0.6233\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 44s 342ms/step - loss: 0.8779 - accuracy: 0.6344 - val_loss: 0.9212 - val_accuracy: 0.6262\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 44s 338ms/step - loss: 0.8474 - accuracy: 0.6461 - val_loss: 0.9459 - val_accuracy: 0.6243\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 44s 340ms/step - loss: 0.8392 - accuracy: 0.6554 - val_loss: 1.0009 - val_accuracy: 0.5998\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 44s 342ms/step - loss: 0.8220 - accuracy: 0.6612 - val_loss: 0.9240 - val_accuracy: 0.6135\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Unfreeze top layers of the base model\n",
    "for layer in base_model.layers[-8:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile with a lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    ModelCheckpoint(\"best_tomato_model.h5\", save_best_only=True, monitor='val_loss')\n",
    "]\n",
    "\n",
    "# Fine-tune the model\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d63d8c-03fa-4e74-a961-850ee4a04901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0016c490-d7e6-4b32-9002-8b7f608a769e",
   "metadata": {},
   "source": [
    "## MobileNETV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e83480e3-2665-41cc-aa18-baf8a86cbe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf6081e3-2c9c-4087-b96f-4c185eb4b8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load MobileNetV2 base\n",
    "base_model = MobileNetV2(input_shape=IMG_SIZE + (3,), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False  # Freeze the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4453f7d5-5125-45fe-a689-86eaca95f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "inputs = Input(shape=IMG_SIZE + (3,))\n",
    "x = base_model(inputs, training=False)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "outputs = Dense(5, activation='softmax')(x)\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce64568a-2627-4c07-866e-3505dd6f4fd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "129/129 [==============================] - 37s 266ms/step - loss: 1.5349 - accuracy: 0.4398 - val_loss: 1.3803 - val_accuracy: 0.4638\n",
      "Epoch 2/15\n",
      "129/129 [==============================] - 36s 278ms/step - loss: 1.3163 - accuracy: 0.5356 - val_loss: 1.2828 - val_accuracy: 0.5029\n",
      "Epoch 3/15\n",
      "129/129 [==============================] - 35s 268ms/step - loss: 1.2250 - accuracy: 0.5580 - val_loss: 1.2276 - val_accuracy: 0.5137\n",
      "Epoch 4/15\n",
      "129/129 [==============================] - 34s 261ms/step - loss: 1.1919 - accuracy: 0.5576 - val_loss: 1.2104 - val_accuracy: 0.5049\n",
      "Epoch 5/15\n",
      "129/129 [==============================] - 35s 268ms/step - loss: 1.1663 - accuracy: 0.5610 - val_loss: 1.1676 - val_accuracy: 0.5352\n",
      "Epoch 6/15\n",
      "129/129 [==============================] - 34s 263ms/step - loss: 1.1293 - accuracy: 0.5685 - val_loss: 1.1394 - val_accuracy: 0.5548\n",
      "Epoch 7/15\n",
      "129/129 [==============================] - 34s 262ms/step - loss: 1.0920 - accuracy: 0.5861 - val_loss: 1.1256 - val_accuracy: 0.5519\n",
      "Epoch 8/15\n",
      "129/129 [==============================] - 35s 271ms/step - loss: 1.0964 - accuracy: 0.5832 - val_loss: 1.1163 - val_accuracy: 0.5558\n",
      "Epoch 9/15\n",
      "129/129 [==============================] - 35s 270ms/step - loss: 1.0629 - accuracy: 0.5949 - val_loss: 1.0890 - val_accuracy: 0.5705\n",
      "Epoch 10/15\n",
      "129/129 [==============================] - 34s 261ms/step - loss: 1.0578 - accuracy: 0.5978 - val_loss: 1.1068 - val_accuracy: 0.5411\n",
      "Epoch 11/15\n",
      "129/129 [==============================] - 35s 270ms/step - loss: 1.0527 - accuracy: 0.5949 - val_loss: 1.0704 - val_accuracy: 0.5773\n",
      "Epoch 12/15\n",
      "129/129 [==============================] - 34s 264ms/step - loss: 1.0495 - accuracy: 0.5959 - val_loss: 1.0778 - val_accuracy: 0.5675\n",
      "Epoch 13/15\n",
      "129/129 [==============================] - 34s 260ms/step - loss: 1.0310 - accuracy: 0.6066 - val_loss: 1.0819 - val_accuracy: 0.5558\n",
      "Epoch 14/15\n",
      "129/129 [==============================] - 34s 267ms/step - loss: 1.0309 - accuracy: 0.6015 - val_loss: 1.0453 - val_accuracy: 0.5832\n",
      "Epoch 15/15\n",
      "129/129 [==============================] - 33s 256ms/step - loss: 1.0171 - accuracy: 0.6068 - val_loss: 1.0577 - val_accuracy: 0.5763\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    ModelCheckpoint('mobilenetv2_best_model.h5', save_best_only=True, monitor='val_loss')\n",
    "]\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a45fa09f-b138-4a8a-a081-b2f191cc6103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "129/129 [==============================] - 38s 268ms/step - loss: 0.9757 - accuracy: 0.6151 - val_loss: 1.0634 - val_accuracy: 0.5881\n",
      "Epoch 2/15\n",
      "129/129 [==============================] - 34s 265ms/step - loss: 0.9132 - accuracy: 0.6393 - val_loss: 1.0209 - val_accuracy: 0.5851\n",
      "Epoch 3/15\n",
      "129/129 [==============================] - 35s 268ms/step - loss: 0.8850 - accuracy: 0.6434 - val_loss: 0.9860 - val_accuracy: 0.5822\n",
      "Epoch 4/15\n",
      "129/129 [==============================] - 34s 267ms/step - loss: 0.8529 - accuracy: 0.6549 - val_loss: 0.9613 - val_accuracy: 0.6233\n",
      "Epoch 5/15\n",
      "129/129 [==============================] - 34s 264ms/step - loss: 0.8350 - accuracy: 0.6695 - val_loss: 0.9838 - val_accuracy: 0.5969\n",
      "Epoch 6/15\n",
      "129/129 [==============================] - 34s 261ms/step - loss: 0.8202 - accuracy: 0.6668 - val_loss: 0.9804 - val_accuracy: 0.5832\n",
      "Epoch 7/15\n",
      "129/129 [==============================] - 35s 273ms/step - loss: 0.8061 - accuracy: 0.6744 - val_loss: 0.9416 - val_accuracy: 0.6145\n",
      "Epoch 8/15\n",
      "129/129 [==============================] - 35s 269ms/step - loss: 0.7904 - accuracy: 0.6783 - val_loss: 1.0470 - val_accuracy: 0.5656\n",
      "Epoch 9/15\n",
      "129/129 [==============================] - 34s 262ms/step - loss: 0.7638 - accuracy: 0.6888 - val_loss: 0.9998 - val_accuracy: 0.5822\n",
      "Epoch 10/15\n",
      "129/129 [==============================] - 36s 277ms/step - loss: 0.7536 - accuracy: 0.6898 - val_loss: 0.9321 - val_accuracy: 0.6057\n",
      "Epoch 11/15\n",
      "129/129 [==============================] - 36s 281ms/step - loss: 0.7323 - accuracy: 0.7020 - val_loss: 0.9348 - val_accuracy: 0.6135\n",
      "Epoch 12/15\n",
      "129/129 [==============================] - 34s 265ms/step - loss: 0.7224 - accuracy: 0.7010 - val_loss: 0.9910 - val_accuracy: 0.5783\n",
      "Epoch 13/15\n",
      "129/129 [==============================] - 34s 264ms/step - loss: 0.7156 - accuracy: 0.7110 - val_loss: 0.9354 - val_accuracy: 0.6096\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze top layers of the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Optionally: Freeze lower layers (to avoid overfitting and save time)\n",
    "for layer in base_model.layers[:-50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with lower learning rate for fine-tuning\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Continue training (fine-tuning phase)\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=15,\n",
    "    callbacks=callbacks,  # EarlyStopping and Checkpoint\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851315f0-2736-40ab-a274-48d4e4ecf3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba378d48-a341-4624-91a6-c60c73d44b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
